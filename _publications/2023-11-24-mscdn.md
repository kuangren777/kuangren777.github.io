---
title: "Multi-sensor based strategy learning with deep reinforcement learning for unmanned ground vehicle"
collection: publications
category: manuscripts
permalink: /publication/2023-11-24-mscdn
excerpt: 'This paper proposes the Multi-Sensor Collaborative Decision Network (MSCDN), a framework that utilizes deep reinforcement learning and attention mechanisms to improve UGV obstacle avoidance and enable Sim2Real transfer. Published in <b>International Journal of Intelligent Networks</b>.'
date: 2023-11-24
venue: 'International Journal of Intelligent Networks'
paperurl: 'https://doi.org/10.1016/j.ijin.2023.11.003'
citation: '<b>Luo, Mingyu.</b> "Multi-sensor based strategy learning with deep reinforcement learning for unmanned ground vehicle." International Journal of Intelligent Networks 4 (2023): 325-336.'
---

## Abstract

As intelligent Unmanned Ground Vehicles (UGVs) operate in increasingly complex scenarios, the fusion of multiple sensors becomes crucial for robust perception and decision-making. Existing methods often struggle with either single-sensor limitations or the redundancy introduced by naive data concatenation. In this paper, we introduce the **Multi-Sensor Collaborative Decision Network (MSCDN)**, a deep reinforcement learning framework designed specifically for UGVs. MSCDN employs a multi-sensor attention fusion network to adaptively integrate data from cameras, LiDAR, and velocity sensors. Validated in both high-fidelity simulations (Unity) and real-world scenarios (AgileX LIMO), MSCDN achieves a **35.71% higher success rate** and a **37.5% faster task completion time** compared to baseline methods, demonstrating superior capability in autonomous obstacle avoidance and zero-shot Sim2Real transfer.

## Motivation

* **Limitations of Single Sensors**: Relying on a single sensor type (e.g., only a camera) leaves UGVs vulnerable to blind spots and environmental noise, limiting their adaptability in dynamic settings.
* **Inefficiency of Traditional Fusion**: Standard fusion methods, such as element-wise addition or direct concatenation of feature vectors, often lead to data redundancy or bloated dimensionality. This hampers the training efficiency of Deep Reinforcement Learning (DRL) agents.
* **The Sim2Real Gap**: Transferring navigation policies from simulation to the real world is challenging due to discrepancies in physical dynamics and sensor noise. A robust mechanism is needed to bridge this gap without extensive retraining.

## Methodology

![The structure of Multi-Sensor Collaborative Decision Network](/images/pub/mscdn/fig2.png)
*Figure 1: The MSCDN architecture integrating Multi-Sensor Attention with Soft Actor-Critic training.*

The MSCDN framework operates through a three-stage pipeline designed to optimize autonomous strategy learning:

1.  **Multi-Sensor Attention Fusion**:
    * The system inputs data from three distinct sources: **Camera** (visual information), **LiDAR** (distance/depth), and **Velocity** (vehicle state).
    * Instead of simple concatenation, an **Attention Layer** dynamically calculates weights ($$\alpha_C, \alpha_L, \alpha_V$$) for each sensor. This allows the UGV to prioritize the most relevant sensor data based on the current environmental context (e.g., relying more on LiDAR when visual data is noisy).
2.  **Soft Actor-Critic (SAC) Training**:
    * The fused state representation is fed into an Actor-Critic architecture trained using the **Soft Actor-Critic (SAC)** algorithm. SAC maximizes entropy to balance exploration and exploitation, ensuring robust policy learning in continuous action spaces.
3.  **Sim2Real Implementation**:
    * A high-fidelity simulation environment is built in **Unity** to mirror real-world physics and layouts.
    * The model employs **Domain Randomization** (varying lighting, obstacle positions) during training.
    * The trained policy is transferred **zero-shot** to a real-world AgileX LIMO robot, utilizing ROS (Robot Operating System) to map sensor inputs directly to the learned network.

## Key Results

* **Superior Performance**: In comparative experiments against baselines like PPO, DDPG, and standard SAC (without attention), MSCDN achieved a **95% success rate** in obstacle avoidance tasks, significantly outperforming the best baseline (PPO) which achieved 70%.
* **Efficiency**: The attention mechanism allowed the model to converge faster, reducing the training steps required to reach optimal performance by **58.33%** compared to baselines.
* **Robustness to Noise**: Ablation studies demonstrated that MSCDN dynamically adjusts attention weights when specific sensors are injected with noise, maintaining high success rates even when individual sensors are compromised.
* **Real-World Validation**: The policy successfully transferred to the physical LIMO robot, enabling it to navigate complex paths and avoid both static and dynamic obstacles (such as moving pedestrians) effectively.

![Avoiding dynamic obstacles in Sim and Real environments](/images/pub/mscdn/fig1112.png)
*Figure 2: Comparison of obstacle avoidance behavior in Simulation vs. Real World scenarios.*